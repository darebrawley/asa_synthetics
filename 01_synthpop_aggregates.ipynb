{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating synthpop synthetic populations to tract level\n",
    "1. read in individual csv files containing synthetic populations\n",
    "2. combine into one large dataframe\n",
    "3. group by tract to aggregate counts\n",
    "4. compute new implied variable\n",
    "5. export as csv to join to tract boundaries in gis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "# library for path names\n",
    "import glob \n",
    "from functools import reduce\n",
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compiling dataframe from folder of individual csv files\n",
    "def compile_df(pathfile_name):\n",
    "    li = []\n",
    "    all_files = glob.glob(pathfile_name)\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, converters={'tract': lambda x: str(x)})\n",
    "        li.append(df)\n",
    "    return(pd.concat(li, axis=0, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating household-level synthetic population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating household level variables/tables\n",
    "households_meck_comp = compile_df(\"data_outputs/20190323_run/*households.csv\")\n",
    "households_meck_comp.to_csv(\"data_outputs/20190323_compiled/households_meck.csv\")\n",
    "\n",
    "# converting columns to correct data type\n",
    "households_meck = pd.read_csv(\"data_outputs/20190323_compiled/households_meck.csv\", \n",
    "                       header=0, dtype={'puma00':str, 'puma10':str, 'NP':int,\n",
    "                                        'TYPE':int,'race_of_head':str,\n",
    "                                        'hispanic_head':str, 'age_of_head':int,\n",
    "                                        'hh_age_of_head':str, 'hh_cars':str,\n",
    "       'hh_children':str, 'hh_income':str, 'hh_race_of_head':str, 'hh_size':str, 'hh_workers':str,\n",
    "       'seniors':str, 'sf_detached':str, 'tenure_mover':str,'state':str, 'county':str,\n",
    "       'tract':str, 'block group':str  \n",
    "                       })\n",
    "## dropping variables we are not using\n",
    "households_var = households_meck.drop(columns=['Unnamed: 0.1', 'serialno', 'RT', 'puma00', 'puma10',\n",
    "       'NP', 'TYPE', 'BLD', 'TEN', 'VEH', 'HINCP', 'MV', 'R18', 'R65',\n",
    "       'race_of_head', 'hispanic_head', 'age_of_head', 'workers',\n",
    "       'hh_age_of_head', 'hh_children', 'hh_race_of_head',\n",
    "       'hh_size', 'hh_workers', 'seniors', 'sf_detached', 'tenure_mover',\n",
    "       'cat_id', 'state', 'county', 'block group'])\n",
    "\n",
    "## aggregating households by cars and tract\n",
    "households_meck_tract_cars = households_var.groupby([\"tract\",\"hh_cars\"]).count()\n",
    "households_meck_tract_income = households_var.groupby([\"tract\",\"hh_income\"]).count()\n",
    "households_meck_tract_tot = households_var.groupby([\"tract\"]).count()\n",
    "\n",
    "# resetting index and unstacking to make a wide data frame\n",
    "house_cars = households_meck_tract_cars.reset_index().pivot(index='tract', columns='hh_cars', values ='Unnamed: 0').fillna(0)\n",
    "house_income = households_meck_tract_income.reset_index().pivot(index='tract', columns='hh_income', values ='Unnamed: 0').fillna(0) \n",
    "house_tot = households_meck_tract_tot.drop(columns={'hh_cars','hh_income'}).rename(columns={'Unnamed: 0':'total'})\n",
    "# households_synth = house_cars.merge(house_income,how='outer', on=\"tract\")\n",
    "households = [house_tot,house_income,house_cars]\n",
    "households_synth = reduce(lambda left,right: pd.merge(left,right,on=\"tract\"),households)\n",
    "\n",
    "\n",
    "##adding prefix to columns\n",
    "households_synth.columns = ['s_' + str(col) for col in households_synth.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hh_cars</th>\n",
       "      <th>hh_income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tract</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000100</th>\n",
       "      <td>2820</td>\n",
       "      <td>2820</td>\n",
       "      <td>2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000300</th>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000400</th>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000500</th>\n",
       "      <td>2492</td>\n",
       "      <td>2492</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000600</th>\n",
       "      <td>1567</td>\n",
       "      <td>1567</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  hh_cars  hh_income\n",
       "tract                                 \n",
       "000100        2820     2820       2820\n",
       "000300         481      481        481\n",
       "000400        1762     1762       1762\n",
       "000500        2492     2492       2492\n",
       "000600        1567     1567       1567"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "households_meck_tract_tot = households_var.groupby([\"tract\"]).count()\n",
    "households_meck_tract_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating person-level synthetic population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person level data\n",
    "persons_meck_comp = compile_df(\"data_outputs/20190323_run/*persons.csv\")\n",
    "persons_meck_comp.to_csv(\"data_outputs/20190323_compiled/persons_meck.csv\")\n",
    "persons_meck = pd.read_csv(\"data_outputs/20190323_compiled/persons_meck.csv\",\n",
    "                                 header=0, dtype = {'AGEP':int,\n",
    "       'RELP':int, 'SEX':str,'HISP':str, 'RAC1P':str,\n",
    "       'hispanic':str, 'person_age':str, 'person_sex':str, 'race':str,\n",
    "       'state':str, 'county':str, 'tract':str, 'block group':str})\n",
    "\n",
    "# # aggregating for total pop person level data\n",
    "persons_var = persons_meck.drop(columns=['Unnamed: 0.1', 'serialno', 'SPORDER', 'puma00', 'puma10',\n",
    "       'AGEP', 'JWTR', 'RELP', 'SCH', 'SCHL', 'SEX', 'WKHP', 'ESR', 'HISP',\n",
    "       'PERNP', 'RAC1P',\n",
    "       'cat_id', 'hh_id', 'state', 'county', 'block group'])\n",
    "persons_tract_tot = persons_var.groupby([\"tract\"]).count()\n",
    "persons_tract_age = persons_var.groupby([\"tract\",\"person_age\"]).count()\n",
    "persons_tract_sex = persons_var.groupby([\"tract\",\"person_sex\"]).count()\n",
    "persons_tract_race = persons_var.groupby([\"tract\",\"race\"]).count()\n",
    "persons_tract_hisp = persons_var.groupby([\"tract\",\"hispanic\"]).count()\n",
    "\n",
    "## resetting index and unstacking to make a wide data frame\n",
    "persons_tract_tot = persons_tract_tot.drop(columns = ['hispanic','person_age','person_sex',\n",
    "                                  'race']).rename(columns={'Unnamed: 0':'total'})\n",
    "persons_tract_age = persons_tract_age.reset_index().pivot(index='tract',columns=\"person_age\", values=\"Unnamed: 0\").dropna(0)\n",
    "persons_tract_sex = persons_tract_sex.reset_index().pivot(index='tract',columns=\"person_sex\", values=\"Unnamed: 0\").dropna(0)\n",
    "persons_tract_race = persons_tract_race.reset_index().pivot(index='tract',columns=\"race\", values=\"Unnamed: 0\").dropna(0)\n",
    "persons_tract_hisp = persons_tract_hisp.reset_index().pivot(index='tract',columns=\"hispanic\",values=\"Unnamed: 0\").dropna(0)\n",
    "persons = [persons_tract_tot,persons_tract_age, persons_tract_sex, persons_tract_race,persons_tract_hisp ]\n",
    "persons_synth = reduce(lambda left,right: pd.merge(left,right,on=\"tract\"),persons)\n",
    "\n",
    "## adding prefix to columns\n",
    "persons_synth.columns = ['s_' + str(col) for col in persons_synth.columns]\n",
    "persons_synth= persons_synth.rename(columns = {\"s_no\":\"s_nonhispanic\",\"s_yes\":\"s_hispanic\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining with ACS estimates and Margins of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in acs estimates\n",
    "ACS_people = pd.read_csv(\"data_outputs/20190330_census_aggregates/37119_people_meck.csv\", converters={'tract': lambda x: str(x)})\n",
    "ACS_households = pd.read_csv(\"data_outputs/20190330_census_aggregates/37119_households_meck.csv\", converters={'tract': lambda x: str(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging acs estimates with synthetics\n",
    "people = ACS_people.merge(persons_synth,how='outer',on='tract')\n",
    "households = ACS_households.merge(households_synth, how='outer',\n",
    "                                  on='tract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a geo id to assist with gis table join \n",
    "people['geoid'] = '37119' + people['tract'].astype(str)\n",
    "households['geoid'] = '37119' + households['tract'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tract', '19 and under', '19 and under_me', '20 to 35', '20 to 35_me',\n",
       "       '35 to 60', '35 to 60_me', 'above 60', 'above 60_me', 'nonhispanic',\n",
       "       'nonhispanic_me', 'hispanic', 'hispanic_me', 'total', 'total_me',\n",
       "       'asian', 'asian_me', 'black', 'black_me', 'other', 'other_me', 'white',\n",
       "       'white_me', 'female', 'female_me', 'male', 'male_me', 's_total',\n",
       "       's_19 and under', 's_20 to 35', 's_35 to 60', 's_above 60', 's_female',\n",
       "       's_male', 's_asian', 's_black', 's_other', 's_white', 's_nonhispanic',\n",
       "       's_hispanic', 'geoid', 'd_19und', 'd_202035', 'd_35to60', 'd_60up',\n",
       "       'd_hispanic', 'd_total', 'd_white', 'd_asian', 'd_black', 'd_other',\n",
       "       'd_female', 'd_male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing people difference columns\n",
    "people['d_19und']= people['s_19 and under']-people['19 and under']\n",
    "people['d_202035']= people['s_20 to 35'] - people['20 to 35'] \n",
    "people['d_35to60']= people['s_35 to 60'] - people['35 to 60']\n",
    "people['d_60up']= people['s_above 60']- people['above 60']\n",
    "people['d_hispanic']= people['s_hispanic']-people['hispanic']\n",
    "people['d_total']= people['s_total']- people['total']\n",
    "people['d_white']= people['s_white']-people['white']\n",
    "people['d_asian']= people['s_asian']-people['asian']\n",
    "people['d_black']= people['s_black']-people['black']\n",
    "people['d_other']= people['s_other']-people['other']\n",
    "people['d_female']= people['s_female']-people['female']\n",
    "people['d_male']= people['s_male']-people['male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing household difference columns\n",
    "households['d_none_car']= households['s_none']-households['none']\n",
    "households['d_one_car']=households['s_one']-households['one']\n",
    "households['d_twomore_car']=households['s_two or more']-households['two or more']\n",
    "households['d_totalhh']= households['s_total']-households['total']\n",
    "households['d_lt30']=households['s_lt30']-households['lt30']\n",
    "households['d_gt30-lt60']=households['s_gt30-lt60']-households['gt30-lt60']\n",
    "households['d_gt60-lt100']=households['s_gt60-lt100']-households['gt60-lt100']\n",
    "households['d_gt100-lt150']=households['s_gt100-lt150']-households['gt100-lt150']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting combined tables to csv for GIS work\n",
    "people.to_csv(\"data_outputs/20190330_ACS_SyntheticsForGIS/37119_people_var_tract.csv\")\n",
    "households.to_csv(\"data_outputs/20190330_ACS_SyntheticsForGIS/37119_households_var_tract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tract', 'none', 'none_me', 'one', 'one_me', 'two or more',\n",
       "       'two or more_me', 'total', 'total_me', 'gt100-lt150', 'gt100-lt150_me',\n",
       "       'gt150', 'gt150_me', 'gt30-lt60', 'gt30-lt6_me', 'gt60-lt100',\n",
       "       'gt60-lt100_me', 'lt30', 'lt30_me', 's_total', 's_gt100-lt150',\n",
       "       's_gt150', 's_gt30-lt60', 's_gt60-lt100', 's_lt30', 's_none', 's_one',\n",
       "       's_two or more', 'geoid', 'd_none_car', 'd_one_car', 'd_twomore_car',\n",
       "       'd_totalhh', 'd_lt30', 'd_gt30-lt60', 'd_gt60-lt100', 'd_gt100-lt150'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "households.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
